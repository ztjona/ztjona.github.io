<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Jonathan A. Zea </title> <meta name="author" content="Jonathan A. Zea"> <meta name="description" content="AI researcher. "> <meta name="keywords" content="Machine Learning, Deep Learning, AI safety"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%E2%80%8D%F0%9F%94%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ztjona.github.io/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Jonathan</span> A. Zea </h1> <p class="desc"></p> <p>Research assistant at Ecuadorean Artificial Intelligence and Computer Vision Lab.</p> <p>Escuela Politécnica Nacional.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/robot_no_people-480.webp 480w,/assets/img/robot_no_people-800.webp 800w,/assets/img/robot_no_people-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/robot_no_people.png?b4f7fdd06ffe5e8bef7f273fee07237b" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="robot_no_people.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>Office 404, Building 20</p> <p>Campus Politécnico</p> <p>“José Rubén Orellana”</p> <p>Quito-Ecuador</p> </div> </div> <div class="clearfix"> <p>You can also visit my profile on our <a href="https://laboratorio-ia.epn.edu.ec/en/members/m_members-active/31-msc-jonathan-zea" rel="external nofollow noopener" target="_blank">lab’s website</a>.</p> <p>Currently, I am pursuing a PhD on AI Safety and Alignment. My areas of interest include Deep Learning, Machine Learning, Neural Networks, Algorithms, and the intersection of AI and Philosophy.</p> <p>In a broader context, I am passionate about microcontrollers, embedded systems, robotics and technology.</p> <p>Beyond that, I am also interested about literature, climate change, puzzles and board games.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 22, 2024</th> <td> <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> Starting PhD. program in Computer Science at Escuela Politécnica Nacional, Quito-Ecuador. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 19, 2024</th> <td> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Creating this personal website. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 07, 2024</th> <td> <img class="emoji" title=":label:" alt=":label:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3f7.png" height="20" width="20"> <em>CNN-LSTM and post-processing for EMG-based hand gesture recognition</em> has been accepted for publication in the journal “Intelligent Systems with Applications”. View the paper <a href="https://www.sciencedirect.com/science/article/pii/S2667305324000280" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Francis-paper-480.webp 480w,/assets/img/publication_preview/Francis-paper-800.webp 800w,/assets/img/publication_preview/Francis-paper-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/Francis-paper.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Francis-paper.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="BARONA-LOPEZ-cnnlstm" class="col-sm-8"> <div class="title">CNN-LSTM and post-processing for EMG-based hand gesture recognition</div> <div class="author"> Lorena Isabel Barona López , Francis M. Ferri , <em>Jonathan Zea</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ángel Leonardo Valdivieso Caraguay, Marco E. Benalcázar' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Intelligent Systems with Applications</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/CNN-francis.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="https://doi.org/10.1016/j.iswa.2024.200352"></span> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1016/j.iswa.2024.200352" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=yMiaYkYAAAAJ&amp;citation_for_view=yMiaYkYAAAAJ:eQOLeE2rZwMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Hand Gesture Recognition (HGR) using electromyography (EMG) signals is a challenging problem due to the variability and noise in the signals across individuals. This study addresses this challenge by examining the effect of incorporating a post-processing algorithm, which filters the sequence of predictions and removes spurious labels, on the performance of a HGR model based on spectrograms and Convolutional Neural Networks (CNN). The study also compares CNN vs CNN-LSTM to assess the influence of the memory cells on the model. The EMG-EPN-612 dataset, which contains measurements of EMG signals for 5 hand gestures from 612 subjects, was used for training and testing. The results showed that the post-processing algorithm increased the recognition accuracy by 41.86% for the CNN model and 24.77% for the CNN-LSTM model. The inclusion of the memory cells increased accuracy by 3.29%, but at the cost of 53 times more learnables. The CNN-LSTM model with post-processing achieved a mean recognition accuracy of 90.55% (SD=9.45%). These findings suggest new paths for research in HGR architectures beyond the traditional focus on the classification and feature extraction stages. For reproducibility purposes, we made publicly available the source code in Github.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">BARONA-LOPEZ-cnnlstm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CNN-LSTM and post-processing for EMG-based hand gesture recognition}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Intelligent Systems with Applications}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{22}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2667-3053}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.iswa.2024.200352}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2667305324000280}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Barona López}, Lorena Isabel and Ferri, Francis M. and Zea, Jonathan and {Valdivieso Caraguay}, Ángel Leonardo and Benalcázar, Marco E.}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Hand gesture recognition, EMG-EPN-612, Post-processing, Convolutional neural networks, Long short-term memory, EMG, Spectrogram}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{eQOLeE2rZwMC}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fist-480.webp 480w,/assets/img/publication_preview/fist-800.webp 800w,/assets/img/publication_preview/fist-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/fist.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fist.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zea2021opensource" class="col-sm-8"> <div class="title">An Open-Source Data Acquisition and Manual Segmentation System for Hand Gesture Recognition based on EMG</div> <div class="author"> <em>Jonathan Zea</em>, <a href="https://laboratorio-ia.epn.edu.ec/en/members-h/35-dr-marco-benalcazar" rel="external nofollow noopener" target="_blank">Marco E. Benalcázar</a>, Lorena Isabel Barona Lôpez , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Ángel Leonardo Valdivieso Caraguay' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 2021 IEEE Fifth Ecuador Technical Chapters Meeting (ETCM)</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/ETCM53643.2021.9590811"></span> <span class="__dimensions_badge_embed__" data-doi="10.1109/ETCM53643.2021.9590811" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=yMiaYkYAAAAJ&amp;citation_for_view=yMiaYkYAAAAJ:Y0pCki6q_DkC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-7-4285F4?logo=googlescholar&amp;labelColor=beige" alt="7 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zea2021opensource</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zea, Jonathan and Benalcázar, Marco E. and Barona Lôpez, Lorena Isabel and Valdivieso Caraguay, Ángel Leonardo}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE Fifth Ecuador Technical Chapters Meeting (ETCM)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Open-Source Data Acquisition and Manual Segmentation System for Hand Gesture Recognition based on EMG}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Data acquisition;Gesture recognition;Manuals;Standardization;Electromyography;Physiology;HGR;Hand Gesture Recognition;Myo Armband;gForce Pro;Matlab;EMG}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ETCM53643.2021.9590811}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Y0pCki6q_DkC}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/italian-480.webp 480w,/assets/img/publication_preview/italian-800.webp 800w,/assets/img/publication_preview/italian-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/italian.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="italian.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="saggio2020sign" class="col-sm-8"> <div class="title">Sign Language Recognition Using Wearable Electronics: Implementing k-Nearest Neighbors with Dynamic Time Warping and Convolutional Neural Network Algorithms</div> <div class="author"> Giovanni Saggio , Pietro Cavallo , Mariachiara Ricci , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Vito Errico, Jonathan Zea, Marco E. Benalcázar' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Sensors</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/saggio.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.3390/s20143879"></span> <span class="__dimensions_badge_embed__" data-doi="10.3390/s20143879" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=yMiaYkYAAAAJ&amp;citation_for_view=yMiaYkYAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-44-4285F4?logo=googlescholar&amp;labelColor=beige" alt="44 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We propose a sign language recognition system based on wearable electronics and two different classification algorithms. The wearable electronics were made of a sensory glove and inertial measurement units to gather fingers, wrist, and arm/forearm movements. The classifiers were k-Nearest Neighbors with Dynamic Time Warping (that is a non-parametric method) and Convolutional Neural Networks (that is a parametric method). Ten sign-words were considered from the Italian Sign Language: cose, grazie, maestra, together with words with international meaning such as google, internet, jogging, pizza, television, twitter, and ciao. The signs were repeated one-hundred times each by seven people, five male and two females, aged 29–54 y ± 10.34 (SD). The adopted classifiers performed with an accuracy of 96.6% ± 3.4 (SD) for the k-Nearest Neighbors plus the Dynamic Time Warping and of 98.0% ± 2.0 (SD) for the Convolutional Neural Networks. Our system was made of wearable electronics among the most complete ones, and the classifiers top performed in comparison with other relevant works reported in the literature.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">saggio2020sign</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Saggio, Giovanni and Cavallo, Pietro and Ricci, Mariachiara and Errico, Vito and Zea, Jonathan and Benalcázar, Marco E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Sign Language Recognition Using Wearable Electronics: Implementing k-Nearest Neighbors with Dynamic Time Warping and Convolutional Neural Network Algorithms}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Sensors}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">article-number</span> <span class="p">=</span> <span class="s">{3879}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/1424-8220/20/14/3879}</span><span class="p">,</span>
  <span class="na">pubmedid</span> <span class="p">=</span> <span class="s">{32664586}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1424-8220}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/s20143879}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{2osOgNQ5qMEC}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#a79914"><a href="https://csei.uta.edu.ec/csei2023/#/inicio" rel="external nofollow noopener" target="_blank">CSEI</a></abbr> </div> <div id="zea2019realtimeLSTM" class="col-sm-8"> <div class="title">Real-Time Hand Gesture Recognition: A Long Short-Term Memory Approach with Electromyography</div> <div class="author"> <em>Jonathan A. Zea</em>, and <a href="https://laboratorio-ia.epn.edu.ec/en/members-h/35-dr-marco-benalcazar" rel="external nofollow noopener" target="_blank">Marco E. Benalcázar</a> </div> <div class="periodical"> <em>In Advances and Applications in Computer Science, Electronics and Industrial Engineering</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="https://doi.org/10.1007/978-3-030-33614-1_11"></span> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1007/978-3-030-33614-1_11" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=yMiaYkYAAAAJ&amp;citation_for_view=yMiaYkYAAAAJ:d1gkVwhDpl0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-12-4285F4?logo=googlescholar&amp;labelColor=beige" alt="12 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Hand gestures are a non-verbal type of communication ideally suited for Human-Machine Interaction. Nevertheless, accuracy rates and response times still are a matter of research. One unattended problem has been the difficulty and vagueness of the evaluation of the models proposed in the literature. In this paper, a protocol for evaluating recognition is proposed. A Hand Gesture Recognition system using electromyography signals (EMG) is also presented. This model works in real time, is user dependent and is based in Long Short-Term Memory Networks. The model recognizes 5 different classes (wave in, wave out, fist, open, pinch) apart from the relax state. A data set with 120 people was collected using the commercial device Myo Armband. The data set was divided 50% for tuning and 50% for testing. Following the evaluation protocol proposed, the presented model achieves a 95.79% in classification and a 88.1% in recognition accuracy. An analysis of the characteristics of this model shows the advantage over similar models and its capability for being applied in all sort of fields.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zea2019realtimeLSTM</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zea, Jonathan A. and Benalc{\'a}zar, Marco E.}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Nummenmaa, Jyrki and P{\'e}rez-Gonz{\'a}lez, Federico and Domenech-Lega, Bruno and Vaunat, Jean and Oscar Fern{\'a}ndez-Pe{\~{n}}a, F{\'e}lix}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Real-Time Hand Gesture Recognition: A Long Short-Term Memory Approach with Electromyography}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances and Applications in Computer Science, Electronics and Industrial Engineering}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{155--167}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-33614-1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-030-33614-1_11}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{d1gkVwhDpl0C}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6A%6F%6E%61%74%68%61%6E%20[%64%6F%74]%20%61%20[%64%6F%74]%20%7A%65%61%20&lt;%61%74&gt;%20%69%65%65%65%20&lt;%64%6F%74&gt;%20%6F%72%67" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0001-8263-2682" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=yMiaYkYAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/ztjona" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/jonathan-a-zea" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Contact me for collaboration, research and consultancy projects. </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Jonathan A. Zea. <br> <br> <em>"I find that I don't understand things unless I try to program them."</em> <l> <br> —Donald E. Knuth <br> <br> Last updated: March 19, 2024. </l> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>